# Random Slopes

## Random slopes

### With random effects independent of each other

Some researchers like to conceptualize random slopes as interactions between group and predictor. They are, but we do not estimate every interaction, only their distribution.

We’ll do this first for variation in returns to SES _at the school level_:

$$
MATHGAIN_{ijk} = \beta_{0jk} + \beta_{1k}SES_{ijk} + b_2 MATHKNOW_{jk} + \varepsilon_{ijk}
$$

$$
\beta_{0jk} = b_0 + \eta_{0jk} + \zeta_{0k},\ \beta_{1k} = b_1 + \zeta_{1k}
$$

$$
\eta_{0jk}\sim N(0,\sigma_{\eta_0}^2),\ \zeta_{0k}\sim N(0,\sigma_{\zeta_0}^2),\  \zeta_{1k}\sim N(0,\sigma_{\zeta_1}^2)\ indep
$$

If the ‘returns’ to SES vary by _classroom \(j\) within school \(k\)_, we need to change the index on the beta coefficient in front of SES to use the index ’jk’:

$$
MATHGAIN_{ijk} = \beta_{0jk} + \beta_{1jk}SES_{ijk} + b_2 MATHKNOW_{jk} + \varepsilon_{ijk},
$$

$$
\beta_{0jk} = b_0 + \eta_{0jk} + \zeta_{0k};\  \beta_{1jk} = b_1 + \eta_{1jk} + \zeta_{1k}
$$

$$
\eta_{0jk}\sim N(0,\sigma_{\eta_0}^2),\ \eta_{1jk}\sim N(0,\sigma_{\eta_1}^2),\ \zeta_{0k}\sim N(0,\sigma_{\zeta_0}^2),\ \zeta_{1jk}\sim N(0,\sigma_{\zeta_1}^2) \mbox{ indep.}
$$

We might rearrange the ordering of the random effects to better reflect the nesting: \(‘regression-like’ fixed effects followed by ‘regression-like’ random effects, in the order of nesting.\)

$$
MATHGAIN_{ijk} = b_0 + b_1 SES_{ijk} + b_2 MATHKNOW_{jk} + \zeta_{0k} + \zeta_{1k}SES_{ijk} + \eta_{0jk} + \eta_{1jk}SES_{ijk} + \varepsilon_{ijk}
$$

#### Coding

Without random slopes

```text
fit3 <- lmer(mathgain ~ ses + mathknow + (1 | schoolid/classid), data = dat)
print(summary(fit3))
```

With random slopes

```text
fit4 <- lmer(mathgain ~ ses + mathknow + (ses | schoolid) + (1 | classid), 
    data = dat)
print(summary(fit4))

# Random effects:
#  Groups   Name        Variance  Std.Dev. Corr
#  classid  (Intercept)  104.2211 10.2089      
#  schoolid (Intercept)   93.2231  9.6552      
#           ses            0.1515  0.3893  1.00
#  Residual             1018.5157 31.9142 
```

We can see that there is correlation between random slope and random intercept at school level. To make them independent:

```text
fit4 <- lmer(mathgain ~ ses + mathknow + (0 + ses | schoolid) + (1 | schoolid)
    (1 | classid), data = dat)
print(summary(fit4))

# Random effects:
#  Groups     Name        Variance Std.Dev.
#  classid    (Intercept)  104.64  10.229  
#  schoolid   (Intercept)   92.12   9.598  
#  schoolid.1 ses            0.00   0.000  
#  Residual               1018.66  31.917
```

The random slope in the random-effects portion of the output suggests that we do not have systematic variation in returns to SES at the school level.

Compare models

```text
anova(fit3, fit4, refit = F)

# Models:
# fit3: mathgain ~ ses + mathknow + (1 | schoolid/classid)
# fit4: mathgain ~ ses + mathknow + (0 + ses | schoolid) + (1 | schoolid) + 
# fit4:     (1 | classid)
#      npar   AIC   BIC  logLik deviance Chisq Df Pr(>Chisq)
# fit3    6 10697 10726 -5342.3    10685                    
# fit4    7 10699 10734 -5342.3    10685     0  1          1
```

### With correlation between random effects

$$
MATHGAIN_{ijk} = b_0 + b_1 SES_{ijk} + b_2 MATHKNOW_{jk} + b_3 MATHKIND_{ijk} + \eta_{0jk} + \zeta_{0k} + \zeta_{1k}SES_{ijk} + \varepsilon_{ijk}
$$

$$
\eta_{0jk}\sim N(0,\sigma_{\eta_0}^2),\ \zeta_{0k}\sim N(0,\sigma_{\zeta_0}^2),\  \zeta_{1k}\sim N(0,\sigma_{\zeta_1}^2),\ \varepsilon_{ijk}\sim N(0,\sigma_\varepsilon^2)
$$

$$
BUT\ NOW\ corr(\zeta_{0k},\zeta_{1k}) = \rho_{\zeta_0\zeta_1}, all\ the\ other\ indep.
$$

Correlation is default in R

```text
fit3 <- lmer(mathgain ~ ses + mathknow + (1 | schoolid/classid), data = dat)
print(summary(fit3))

# Random effects:
#  Groups   Name        Variance  Std.Dev. Corr
#  classid  (Intercept)  104.2211 10.2089      
#  schoolid (Intercept)   93.2231  9.6552      
#           ses            0.1515  0.3893  1.00
#  Residual             1018.5157 31.9142 
```

## Wald test

### Sampling Variation

sampling variability: in different samples, we might estimate a different ‘effect’, in other words, they are unstructured

variance of the random effect: describes variation from group to group in a latent variable

### Wald test

#### Example

Say we have two nested models, M1 with fixed effect parameters \(b0, b1, b2\) and M2 with fixed effect parameters \(b0, b1, b2, b3, b4, b5\), and we wish to determine whether the new parameters \(b3, b4, b5\) are significant as a block. 

NOTE: we can this with a LRT. But we learn something important by examining an alternative approach

#### Hypothesis

$$
H_0: {b_3} = {b_4} = {b_5} = 0
$$

#### Formula

$$
Under\ H_0: {b_3} = {b_4} = {b_5} = 0, ({b_3},{b_4},{b_5}){\Sigma ^{ - 1}}({b_3},{b_4},{b_5})' \sim \chi_3^2
$$

$$
\Sigma  = \left( {\begin{array}{*{20}{c}}
{\sigma_3^2}&{{\sigma_3}{\sigma_4}{\rho_{34}}}&{{\sigma_4}{\sigma_5}{\rho_{45}}}\\
{{\sigma_3}{\sigma_4}{\rho_{34}}}&{\sigma_4^2}&{{\sigma_3}{\sigma_5}{\rho_{35}}}\\
{{\sigma_4}{\sigma_5}{\rho_{45}}}&{{\sigma_3}{\sigma_5}{\rho_{35}}}&{\sigma_5^2}
\end{array}} \right)
$$

#### Coding directly

```text
V <- summary(fit1)$vcov
print(V)
V3 <- V[4:6, 4:6]
print(V3)

## 3 x 3 Matrix of class "dsyMatrix"
## mathknow mathprep yearstea
## mathknow 1.73782290 0.00529564 0.00209774
## mathprep 0.00529564 1.74428428 -0.02968643

B3 <- fit1@beta[4:6]
solve(V3)
## 3 x 3 Matrix of class "dsyMatrix"
## [,1] [,2] [,3]
## [1,] 0.575527651 -0.002959856 -0.07124614
## [2,] -0.002959856 0.589705377 0.96334071
## [3,] -0.071246137 0.963340711 56.59026214

W <- t(B3) %*% solve(V3) %*% B3
print(W)

## 1 x 1 Matrix of class "dgeMatrix"
## [,1]
## [1,] 7.187268
```

#### Simple version

```text
require(car)
linearHypothesis(fit1, c("mathknow", "mathprep", "yearstea"))

## Linear hypothesis test
##
## Hypothesis:
## mathknow = 0
## mathprep = 0
## yearstea = 0
##
## Model 1: restricted model
## Model 2: mathgain ~ ses + minority + mathknow + mathprep + yearstea +
## (1 | schoolid) + (1 | classid)
##
## Df Chisq Pr(>Chisq)
## 1
## 2 3 7.1873 0.06616 .
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

