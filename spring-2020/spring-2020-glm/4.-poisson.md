---
description: Model for counts
---

# 4. Poisson

## Poisson Model

#### What determines the counts?

* Occurrence: rate
* Exposure: time

#### Poisson Distribution

![](../../.gitbook/assets/image%20%282%29.png)

Where lambda is the observed number of counts \(given a unit time\). P\(Y=y\) can be read as “the probability of observing y number counts”.

E\(Y\)= λ.  Also, Var\(Y\) =  λ

![](../../.gitbook/assets/image%20%2825%29.png)

#### Model

$$
log(\lambda) = \alpha+\beta_1X_1+\beta_2X_2+...+\beta_nX_n
$$

```text
res =  glm(formula, data, family=poisson(link = "log")
```

#### Difference between poisson and linear regression

You can estimate the sd at the same time, it is not fixed any more.

Also, the distribution of Y is not normal.

#### Interpreting results

![](../../.gitbook/assets/image%20%2827%29.png)

* Being female and having kids under 5 have significantly negative impacts on log\(λ\).
* Hence we expect to see fewer publications for female and those who have kids under 5. 
* Being married and having a mentor who publishes a lot have significantly positive impacts on log\(λ\) 
* The intercept term now is the log\(λ\) for the reference group \(when X variables all take values 0\).

#### Risk ratio

e\(β\) is also called relative incidence ratio or risk ratio.

![](../../.gitbook/assets/image%20%2842%29.png)

#### Model comparison

* Pseudo R square
* `anova(model.a, model.b)`
* LRT and chisq

#### Prediction

* predict the rate of occurrence
* predict the mean of outcome

Offset: number of time periods, exposure

$$
Total=n_i\lambda
$$

```text
res =  glm(incidents~factor(type) + factor(year) +
       offset(log(exposure))
       , data, family=poisson(link = "log")
```

* log\(λ\)=0.3-0.22+0.16-0.18_2+0.012_3+0.026\*8=0.124
* log\(λ \* exposure \)=log\(λ \)+log\(exposure\)=Xβ+log\(exposure\)

## Issue: over-dispersion

variance is greater than what the model predicts

### Diagnosis of Over-dispersion and fix

“Deviance/df” and “Pearson/df” both roughly measure V\(Y\)/E\(Y\). If they are close to 1, then we don’t have an overdispersion problem. If they are much greater than 1, then we have an overdispersion problem.

![](../../.gitbook/assets/image%20%2850%29.png)

So look at Deviance/\(n-p\) or pearson/\(n-p\)

A quick fix to the over-dispersion problem is to scale up the standard errors proportionally, specifically, by a factor of square root of 1.829=1.35. 

```text
#Method 1:
res = glm(formula, data, family = quasipoisson(link="log")
```

\#Method 2: manually

![](../../.gitbook/assets/image%20%288%29.png)

### Negative Binomial

let’s assume that on average, _the rate of occurrence for all the student in the sample is λ_. But we allow each individual to have a different rate of occurrence that is viλ. vi is the individual factor, and it is assumed to have a Gamma distribution with _mean_ _1_ and variance α.

$$
Yi \sim Poisson(v_i\lambda)
\\ v_i\sim Gamma(1,\alpha)
$$

Then

$$
E(Y)= \lambda
\\ V(Y)= \lambda(1+ \alpha \lambda)
$$

#### Model

```text
res = glm.nb(formula, data, init.theta, link = log)
```

### Zero-inflated Poisson Model

![](../../.gitbook/assets/image%20%285%29.png)

```text
library(pscl)
zeroinfl(formula = art~fem+mar+kid5+phd+ment | 1, data = data)
```

In this model, no explanatory variable is used. So for each student there is a common probability of falling into group 1 \(publication=0\). P=exp\(-1.68\)/\(1+exp\(-1.68\)\)=0.16

Example:

![](../../.gitbook/assets/image%20%2875%29.png)

It turns out that mentor's productivity really sets the expectation, or students could self-select to different mentors based on their plan. For each additional paper one's mentor publishes, a student's odds of not wanting to publish would drop by 13%

#### Predict

```text
predict(res, type = "prob"）
predict(res, type = "zero"）
```

